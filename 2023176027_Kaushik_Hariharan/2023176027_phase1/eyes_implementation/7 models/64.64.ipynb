{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 578ms/step - accuracy: 0.3591 - loss: 3.4550 - val_accuracy: 0.5000 - val_loss: 1.8469\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.5148 - loss: 1.8221 - val_accuracy: 0.6200 - val_loss: 1.1395\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.6344 - loss: 0.9768 - val_accuracy: 0.6100 - val_loss: 0.8822\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - accuracy: 0.6747 - loss: 0.8137 - val_accuracy: 0.6400 - val_loss: 0.7421\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - accuracy: 0.7832 - loss: 0.5228 - val_accuracy: 0.6900 - val_loss: 0.7231\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.7725 - loss: 0.4753 - val_accuracy: 0.7000 - val_loss: 0.6944\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - accuracy: 0.8431 - loss: 0.3928 - val_accuracy: 0.7200 - val_loss: 0.6703\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.8467 - loss: 0.3757 - val_accuracy: 0.7400 - val_loss: 0.6335\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - accuracy: 0.9174 - loss: 0.2786 - val_accuracy: 0.8000 - val_loss: 0.5900\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - accuracy: 0.9158 - loss: 0.2651 - val_accuracy: 0.8100 - val_loss: 0.5851\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directories for each class\n",
    "kapha_dir = r'C:\\Users\\kaush\\Downloads\\eyes dataset\\train\\kapha'\n",
    "pittha_dir = r'C:\\Users\\kaush\\Downloads\\eyes dataset\\train\\pittha'\n",
    "vata_dir = r'C:\\Users\\kaush\\Downloads\\eyes dataset\\train\\vata'\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Resize to 64x64\n",
    "            images.append((img, label))  # Append image and its label as tuple\n",
    "    return images\n",
    "\n",
    "# Load images\n",
    "kapha_images = load_images_from_folder(kapha_dir, 0)  \n",
    "pittha_images = load_images_from_folder(pittha_dir, 1) \n",
    "vata_images = load_images_from_folder(vata_dir, 2)\n",
    "\n",
    "# Data Augmentation\n",
    "def augment_images(images, label):\n",
    "    augmented_images = []\n",
    "    for img, _ in images:\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Random cropping\n",
    "        x_start = random.randint(0, int(0.1 * w))\n",
    "        y_start = random.randint(0, int(0.1 * h))\n",
    "        cropped_img = img[y_start:y_start + h - 20, x_start:x_start + w - 20]\n",
    "        cropped_img = cv2.resize(cropped_img, (w, h))\n",
    "        augmented_images.append((cropped_img, label))\n",
    "        \n",
    "        # Scaling\n",
    "        scaled_img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_LINEAR)\n",
    "        scaled_img = cv2.resize(scaled_img, (w, h))\n",
    "        augmented_images.append((scaled_img, label))\n",
    "        \n",
    "        # Random perspective transformation\n",
    "        pts1 = np.float32([[0, 0], [w-1, 0], [0, h-1], [w-1, h-1]])\n",
    "        pts2 = np.float32([\n",
    "            [random.randint(0, w//4), random.randint(0, h//4)],\n",
    "            [random.randint(w-1-w//4, w-1), random.randint(0, h//4)],\n",
    "            [random.randint(0, w//4), random.randint(h-1-h//4, h-1)],\n",
    "            [random.randint(w-1-w//4, w-1), random.randint(h-1-h//4, h-1)]\n",
    "        ])\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        perspective_img = cv2.warpPerspective(img, matrix, (w, h))\n",
    "        augmented_images.append((perspective_img, label))\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# Apply augmentation\n",
    "augmented_kapha_images = augment_images(kapha_images, 0)\n",
    "augmented_pittha_images = augment_images(pittha_images, 1)\n",
    "augmented_vata_images = augment_images(vata_images, 2)\n",
    "\n",
    "# Combine original and augmented images\n",
    "data = kapha_images + pittha_images + vata_images + augmented_kapha_images + augmented_pittha_images + augmented_vata_images\n",
    "X, y = zip(*data)  # Unzip the list of tuples into separate lists\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize images\n",
    "X = X / 255.0  # Scale pixel values to [0, 1]\n",
    "\n",
    "# Reshape X to 64x64x3 for DenseNet121 input\n",
    "X_reshaped = np.repeat(X, 3, axis=-1) if X.shape[-1] == 1 else X\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the DenseNet121 model\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of DenseNet121\n",
    "x = GlobalAveragePooling2D()(base_model.output)  # Global average pooling\n",
    "x = Dense(256, activation='relu')(x)  # Dense layer\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "output_layer = Dense(3, activation='softmax')(x)  # Output layer for 3 classes\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Confusion Matrix and Accuracy Score\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Kapha', 'Pittha', 'Vata'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Predicted Class: Kapha\n",
      "Confidence Scores: [0.92982656 0.06770716 0.00246626]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"C:/Users/kaush/Downloads/f376a5fca76fc505efa982ec34485be0.jpg\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "Predicted Class: Pittha\n",
      "Confidence Scores: [0.00226669 0.9946189  0.00311442]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/704ec85652631ad89c8b2da69d973db6.jpg\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "Predicted Class: Vata\n",
      "Confidence Scores: [0.01780924 0.16625027 0.81594044]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/original.webp\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "Predicted Class: Pittha\n",
      "Confidence Scores: [0.25676748 0.6874551  0.05577736]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/boy-with-green-eyes-india-wernher-krutein.jpg\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "Predicted Class: Kapha\n",
      "Confidence Scores: [0.7572797  0.13148572 0.11123461]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/tumblr_d640ce287cfc90bca04fb5d7ec656471_b5ed8c6d_1280.jpg\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Predicted Class: Pittha\n",
      "Confidence Scores: [0.2329657  0.7078842  0.05915011]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/th (9).jpg\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/kaush/Downloads/cc928123633220550bf53a32362f77a5--kostas-martakis-sexy-men.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"C:/Users/kaush/Downloads/cc928123633220550bf53a32362f77a5--kostas-martakis-sexy-men.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
      "Predicted Class: Kapha\n",
      "Confidence Scores: [0.8886866  0.02170568 0.08960769]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/cc928123633220550bf53a32362f77a5--kostas-martakis-sexy-men.jpg\"  # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Predicted Class: Vata\n",
      "Confidence Scores: [0.00248673 0.06347054 0.93404275]\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 64x64\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Normalize the image (scale pixel values to [0, 1])\n",
    "    img_resized = img_resized / 255.0\n",
    "    \n",
    "    # Ensure the image has 3 channels (for RGB), repeat if grayscale\n",
    "    if img_resized.shape[-1] == 1:  # If the image is grayscale\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)\n",
    "    \n",
    "    # Add an extra dimension for the batch size (1 image in this case)\n",
    "    img_input = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    # Predict with the model\n",
    "    predictions = model.predict(img_input)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Map the predicted class to its label\n",
    "    class_labels = ['Kapha', 'Pittha', 'Vata']\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "    \n",
    "    return predicted_label, predictions[0]\n",
    "\n",
    "# Example usage:\n",
    "image_path =  \"C:/Users/kaush/Downloads/th (10).jpg\" # Replace with the actual path to your image\n",
    "predicted_label, confidence_scores = predict_image(image_path, model)\n",
    "\n",
    "print(f'Predicted Class: {predicted_label}')\n",
    "print(f'Confidence Scores: {confidence_scores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
